2 & 3
2 & 
2 & 4
2 & 5
2 & 6
2 & 7
2 & 8
2 & 9
2 & 0
2 & 1234567890
2 & 123456789
2 & 2
2 & 3
_
import sys
import pexpect
pexpect.re?
pexpect.spawn('sudo airmon-ng start wlan0')
s = pexpect.spawn('sudo airmon-ng start wlan0')
s.
s.expect('assword')?
s.expect()?
s.expect?
print s.before
print s.before()
import pexpect
ls = pexpect.spawn('ls')
ls.expect('EOF')
ls.expect(['EOF'])
ls = pexpect.spawn('ls')
ls.expect(['EOF'])
ls = pexpect.spawn('ls')
ls.before
print ls.before
ls = pexpect.spawn('ls')
pexpect.run(ls)
pexpect.run('ls')
pexpect.run('ls').split('\n')
pexpect.run('ls').split('\n\r')
ptint pexpect.run('ls').split('\n')
a = pexpect.run('ls')
a
print a
print a[1]
print a[111]
print a[11]
print a[:11]
print a[:111]
print a[:5]
print a[:10]
print a[:20]
print a[:30]
print a[:29]
for l in a: print l
a
for l in a: print l
# -*- coding:utf-8 -*-
for l in a: print l
for l in a: print str(l)
import re
re.compile('[a-zA-Z]')
letter = re.compile('[a-zA-Z]')
'i' == letter
'i' is letter
letter.match('l')
letter.search('l')
letter.search?
letter.scanner?
letter.finda?
letter.findall?
letter.finditer?
letter.finditer('ed4fr5gt67ju89ki')
for l in letter.finditer('ed4fr5gt67ju89ki'):
    print l
    
clear()
import BeautifulSoup as bs
doc = ['<html><head><title>Заголовок страницы</title></head>',
       '<body><p id="firstpara" align="center">Это параграф <b>один</b>.',
       '<p id="secondpara" align="blah">Это параграф <b>два</b>.',
       '</html>']
soup = bs.BeautifulSoup(doc)
soup = bs.BeautifulSoup(str(doc))
soup
soup.prettify()
print soup.prettify()
soup = bs.BeautifulSoup("".join(doc))
soup.prettify()
soup = bs.BeautifulSoup(u"".join(doc))
soup = bs.BeautifulSoup(u''.join(doc))
import re
doc = ['<html><head><title>Заголовок страницы</title></head>',
       '<body><p id="firstpara" align="center">Это параграф <b>один</b>.',
       '<p id="secondpara" align="blah">Это параграф <b>два</b>.',
       '</html>']
soup = BeautifulSoup(''.join(doc))
from BeautifulSoup import BeautifulSoup
soup = BeautifulSoup(''.join(doc))
print soup.prettify()
doc = ['<html><head><title>Заголовок страницы</title></head>',
       '<body><p id="firstpara" align="center">Это параграф <b>один</b>.',
       '<p id="secondpara" align="blah">Это параграф <b>два</b>.',
       '</html>']
from BeautifulSoup import BeautifulSoup
soup = BeautifulSoup(''.join(doc))
soup.prettify()
import re
soup.prettify()
doc = ['<html><head><title>Заголовок страницы</title></head>',
       '<body><p id="firstpara" align="center">Это параграф <b>один</b>.',
       '<p id="secondpara" align="blah">Это параграф <b>два</b>.',
       '</html>']
soup = BeautifulSoup(''.join(doc))
soup.prettify()
from BeautifulSoup import BeautifulSoup
import re
doc = ['<html><head><title>Заголовок страницы</title></head>',
       '<body><p id="firstpara" align="center">Это параграф <b>один</b>.',
       '<p id="secondpara" align="blah">Это параграф <b>два</b>.',
       '</html>']
soup = BeautifulSoup(''.join(doc))
soup.prettify()
print soup.prettify()
doc = ['<html><head><title>Заголовок страницы</title></head>',
       '<body><p id="firstpara" align="center">Это параграф <b>один</b>.',
       '<p id="secondpara" align="blah">Это параграф <b>два</b>.',
       '</html>']
from BeautifulSoup import BeautifulSoup
soup = BeautifulSoup(''.join(doc))
soup.prettify()
print soup.prettify()
soup.
soup.contents[0]
soup.contents[0].name
soup.contents[0].contents[0].name
soup.contents[0].contents[0]
doc = ['<html><head><title>Page header</title></head>',
       '<body><p id="firstpara" align="center">This is paragraph<b>один</b>.',
       '<p id="secondpara" align="blah">This is paragraph<b>два</b>.',
       '</html>']
soup = BeautifulSoup(''.join(doc))
soup.contents[0].contents[0].name
soup.contents[0].contents[0]
doc = ['<html><head><title>Заголовок страницы</title></head>',
       '<body><p id="firstpara" align="center">Это параграф <b>один</b>.',
       '<p id="secondpara" align="blah">Это параграф <b>два</b>.',
       '</html>']
soup = BeautifulSoup(''.join(doc))
soup.contents[0].contents[0]
head = soup.contents[0].contents[0]
head
head.name
head.parent.name
print head
print head.next
print head.next.next
print head.next.next.next
print head.nextSibling
print head.nextSibling.next
print head.nextSibling.nextSibling
soup.html
print soup.html
print soup.html.head
print soup.html.body.p
print soup.html.body.p.b
print soup.html.body.parent
print soup.html.string
print soup.html.head.title.string
soup.findAll('p')
print soup.findAll('p')
print soup.findAll('p', align='center')
print soup.find('p', align='center')
print soup.find('p')
print soup.findAll('p')
p = soup.findAll('p')
p
print p
p[0]
print p[0]
print p[1]
print p[1]['b']
soup('p')
soup('p')[0]
print soup('p')[0]
print soup('p')[0]['align']
titleTag['id'] = 'the Title'
titleTag['id'] = 'theTitle'
titleTag = []
titleTag['id'] = 'theTitle'
import lxml
100/6.0
100/3.0
import urllib
import lxml.html
page = urllib.urlopen("http://habrahabr.ru/")
page
doc = lxml.html.document_fromstring(page.read())
page = urllib.urlopen("http://habrahabr.ru/")
doc = lxml.html.document_fromstring(page.read())
page = urllib.urlopen("http://habrahabr.ru/")
page.read()
import urllib
# подключили библиотеку urllib
import lxml.html
# подключили библиотеку lxml
page = urllib.urlopen("http://habrahabr.ru/")
# Открываем наш любимый Хабр
doc = lxml.html.document_fromstring(page.read())
# Получили HTML-код главной страницы Хабра
for topic in doc.cssselect('h2.entry-title a.topic'):
	print topic.text
page = urllib.urlopen("http://habrahabr.ru/")
print doc = lxml.html.document_fromstring(page.read())
lxml.html.document_fromstring(page.read())
me = lxml.html.document_fromstring(page.read())
page = urllib.urlopen("http://habrahabr.ru/")
me = lxml.html.document_fromstring(page.read())
for topic in me.cssselect('h2.entry-title a.topic'):
	print topic.text
 
page = urllib.urlopen("http://habrahabr.ru/")
doc = lxml.html.document_fromstring(page.read())
import sqlite3
conn = sqlite3.connect('/tmp/test.db')
conn.execute('create table person(name, sports)')
data = [(u'Ivan', 33), (u'Maria', 22)]
conn.executemany("insert into person(name,sports) values (?, ?)", data)
conn.commit()
conn.close()
conn = sqlite3.connect('/tmp/test.db')
for row in conn.execute("select * from person"):
    print row[0], row[1]
    
conn.row_factory = sqlite3.Row
cur = conn.cursor()
cur.execute("select * from person")
for row in cur:
    print row['name']
    print row['sports']
    
conn.cursor?
conn.close()
import csv
csv?
csv.reader?
reader = csv.reader()
abitur = open('abitur/data.csv','r')
reader = csv.reader(abitur)
for row in reader:
    print row
    
i=0
data = []
reader = csv.reader(abitur)
for row in reader:
    data[i] = row
    i += 1
    
data
data[1]
data[0]
reader = csv.reader(abitur)
for row in reader:
    data[i] = row
    i += 1
    
data
data = ()
type(data)
for row in reader:
    data[i] = row
    i += 1
    
data
print data
reader = csv.reader(abitur)
for row in reader:
    data[i] = row
    i += 1
    
data
for row in reader:
    print row
    
reader = csv.reader(abitur)
for row in reader:
    print row
    
reader = csv.reader(abitur)
import csv
reader = csv.reader(abitur)
abitur = open('abitur/data.csv','r')
reader = csv.reader(abitur)
for row in reader:
for row in reader:
    hkljfg.vyi
    
abitur = open('abitur/data.csv','r')
reader = csv.reader(abitur)
import csv
reader = csv.reader(abitur)
data = []
i = 0
for row in reader:
    data[i] = row
    i += 1
    
data
data[1] = 'qeqwe'
data(1) = 'qeqwe'
data = []
data[0] = 12

